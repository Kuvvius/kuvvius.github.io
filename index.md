---
layout: page
title: About Me â€“ Jiawei Gu
permalink: /
---


### About Me


I am Jiawei Gu, an MSc student in Computer Science at Sun Yat-sen University. 
I am deeply motivated by the intellectual challenges of Natural Language Processing (NLP) and its intersections with multimodal learning and reasoning. I firmly believe that "pain is inevitable, suffering is optional," and I am ready to embrace the challenges that come with pursuing what I desire. Specifically, during this time, I have delved into research on natural language and multi-modal approaches, shaping me into an independent researcher with clear ideas about future research directions about the following topics:

My research interests include:
* [cite_start]Scaling of Text/Multimodal Reasoning [cite: 24]
* [cite_start]Efficient Learning for Training and Inference [cite: 24]
* [cite_start]Domain Knowledge Injection [cite: 24]


---

### News
- ***May 2025:*** [RAPID](https://arxiv.org/abs/2502.20330) has been accepted to ICML 2025 as Spotlight!
- ***Feb 2025:*** We release the [LongPO](https://www.arxiv.org/pdf/2502.13922), a self-evolving long-context LLM training approach for both context extension and long-context alignment in one stage without external annotation.
- ***Feb 2025:*** [LongPO](https://www.arxiv.org/pdf/2502.13922) has been accepted to ICLR 2025!
- ***Jan 2024:*** [CLEX](https://arxiv.org/abs/2310.16450) has been accepted to ICLR 2024!
- ***Oct 2023:*** We release the [CLEX](https://arxiv.org/abs/2310.16450), a length extrapolation method that enables LLMs to access the context length up to 4x~8x the training length!

---



### Publications

  - [CMR Scaling Law: Predicting Critical Mixture Ratios for Continual Pre-training of Language Models](https://aclanthology.org/2024.emnlp-main.903/)\<br\>
    **Jiawei Gu**, Zacc Yang, Chuanghao Ding, Rui Zhao, Fei Tan.\<br\>
    EMNLP2024, First Author

    \<div class="btn-links"\>
    \<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://aclanthology.org/2024.emnlp-main.903/" target="\_blank" rel="noopener"\>Paper\</a\>
    \<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://drive.google.com/file/d/1XkOUCJcO5Uq2TYD3fE3mKEBGN\_qcosYm/view?usp=sharing" target="\_blank" rel="noopener"\>Oral Presentation\</a\>
    \<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://docs.google.com/presentation/d/1O1PSqvXQAtykU5w2hUVnANbk1UdwkahSPOCiomXBEc0/edit?usp=sharing" target="\_blank" rel="noopener"\>Slides\</a\>
    \</div\>

  - [Can MLLMs Reason in Multimodality? EMMA: An Enhanced MultiModal ReAsoning Benchmark](https://www.arxiv.org/abs/2501.05444)\<br\>
    Yunzhuo Hao\*,\*\*Jiawei Gu\*\*\*, Huichen Will Wang\*, Linjie Li\*, Zhengyuan Yang, Lijuan Wang, Yu Cheng.\<br\>
    ICML2025 (Oral), First author

    \<div class="btn-links"\>
    \<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://www.arxiv.org/abs/2501.05444" target="\_blank" rel="noopener"\>Paper\</a\>
    \<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://emma-benchmark.github.io/" target="\_blank" rel="noopener"\>Homepage\</a\>
    \<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://icml.cc/media/icml-2025/Slides/43702\_JWS4hmd.pdf" target="\_blank" rel="noopener"\>Slides\</a\>
    \<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://event.baai.ac.cn/live/928" target="\_blank" rel="noopener"\>Talk\</a\>
    \</div\>

  - [Boosting Decision-Making Ability of LLMs with Speculative Reward Model Cost-Effectively](https://arxiv.org/abs/2506.00396)\<br\>
    **Jiawei Gu**, Shangsong Liang.\<br\>
    ACL2025 (Oral), First Author

    \<div class="btn-links"\>
    \<a class="btn btn-outline-primary btn-page-header btn-sm" href="[https://arxiv.org/abs/2506.00396](https://arxiv.org/abs/2506.00396)" target="\_blank" rel="noopener"\>Paper\</a\>
    \</div\>

  - [Toward Structured Knowledge Reasoning: Contrastive Retrieval-Augmented Generation on Experience](https://arxiv.org/abs/2506.00842)\<br\>
    **Jiawei Gu**, Ziting Xian, Yuanzhen Xie, Ye Liu, Enjie Liu, Ruichao Zhong, Mochi Gao, Yunzhi Tan, Bo Hu, Zang Li.\<br\>
    ACL2025, First Author

    \<div class="btn-links"\>
    \<a class="btn btn-outline-primary btn-page-header btn-sm" href="[https://arxiv.org/abs/2506.00842](https://arxiv.org/abs/2506.00842)" target="\_blank" rel="noopener"\>Paper\</a\>
    \</div\>

  - [A Survey on LLM-as-a-Judge](https://arxiv.org/abs/2411.15594)\<br\>
    **Jiawei Gu**, Xuhui Jiang, Zhichao Shi, Hexiang Tan, Xuehao Zhai, Chengjin Xu, Wei Li, Yinghan Shen, Shengjie Ma, Honghao Liu, Saizhuo Wang, Kun Zhang, Yuanzhuo Wang, Wen Gao, Lionel Ni, Jian Guo.\<br\>
    Preprint, First author

    \<div class="btn-links"\>
    \<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/2411.15594" target="\_blank" rel="noopener"\>Paper\</a\>
    \<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://awesome-llm-as-a-judge.github.io/" target="\_blank" rel="noopener"\>Homepage\</a\>
    \</div\>

  - [MolRAG: Unlocking the Power of Large Language Models for Molecular Property Prediction]\<br\>
    Ziting Xian, **Jiawei Gu**, Lingbo Li, Shangsong Liang.\<br\>
    ACL2025, Second Author

  - [Scaling Reasoning, Losing Control: Evaluating Instruction Following in Large Reasoning Models](https://arxiv.org/abs/2505.14810)\<br\>
    Tingchen Fu, **Jiawei Gu**, Yafu Li, Xiaoye Qu, Yu Cheng.\<br\>
    Preprint, Second Author

    \<div class="btn-links"\>
    \<a class="btn btn-outline-primary btn-page-header btn-sm" href="[https://arxiv.org/abs/2505.14810](https://arxiv.org/abs/2505.14810)" target="\_blank" rel="noopener"\>Paper\</a\>
    \</div\>

  - [Unfolding Spatial Cognition: Evaluating Multimodal Models on Visual Simulations](https://arxiv.org/abs/2506.04633)\<br\>
    Linjie Li, Mahtab Bigverdi, **Jiawei Gu**, Zixian Ma, Yinuo Yang, Ziang Li, Yejin Choi, Ranjay Krishna.\<br\>
    Preprint, Third Author

    \<div class="btn-links"\>
    \<a class="btn btn-outline-primary btn-page-header btn-sm" href="[https://arxiv.org/abs/2506.04633](https://arxiv.org/abs/2506.04633)" target="\_blank" rel="noopener"\>Paper\</a\>
    \</div\>

  - [FullFront: Benchmarking MLLMs Across the Full Front-End Engineering Workflow](https://arxiv.org/abs/2505.17399)\<br\>
    Haoyu Sun, Huichen Will Wang, **Jiawei Gu**, Linjie Li, Yu Cheng.\<br\>
    Preprint, Third Author

    \<div class="btn-links"\>
    \<a class="btn btn-outline-primary btn-page-header btn-sm" href="[https://arxiv.org/abs/2505.17399](https://arxiv.org/abs/2505.17399)" target="\_blank" rel="noopener"\>Paper\</a\>
    \</div\>



---

### Services

- Conference reviewer: [Neurips 2024](https://neurips.cc/Conferences/2024), [ICLR 2025](https://iclr.cc/), [ICML 2025](https://icml.cc/), [ACL Roling Review ](https://aclrollingreview.org/)

- Journal reviewer: [Neurocomputing](https://www.sciencedirect.com/journal/neurocomputing), [IEEE Transactions on Pattern Analysis and Machine Intelligence](https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34)
<!-- 
# About Me

[cite_start]I am Jiawei Gu, an MSc student in Computer Science at Sun Yat-sen University, expected to graduate in June 2025[cite: 1]. 

[cite_start]My research journey started later than usual due to my volunteer service experience[cite: 20]. [cite_start]However, I possess an unparalleled passion for exploration and scientific inquiry[cite: 21]. [cite_start]Over the past year of dedicated research study, I have solidified my aspiration to contribute to the field of Natural Language Processing (NLP)[cite: 22]. [cite_start]I am actively pursuing this goal, much like my unwavering commitment to morning runs over the past five years[cite: 22]. [cite_start]I firmly believe that "pain is inevitable, suffering is optional" and I am ready to embrace the challenges that come with pursuing what I desire[cite: 23]. [cite_start]Specifically, I have delved into research on natural language and multi-modal approaches, shaping me into an independent researcher with clear ideas about future research directions[cite: 24].

My research interests include:
* [cite_start]Scaling of Text/Multimodal Reasoning [cite: 24]
* [cite_start]Efficient Learning for Training and Inference [cite: 24]
* [cite_start]Domain Knowledge Injection [cite: 24]

---


# News

* [cite_start]**July 2025:** My paper, "[EMMA: An Enhanced MultiModal Reasoning Benchmark](YOUR_EMMA_ARXIV_LINK)"[cite: 6], has been accepted to ICML 2025 as an Oral presentation!
* [cite_start]**July 2025:** My paper, "[Boosting Decision-Making Ability of LLMs with Speculative Reward Model Cost-Effectively](YOUR_SRM_ARXIV_LINK)"[cite: 9], has been accepted to ACL 2025 as an Oral Presentation!
* [cite_start]**July 2025:** My paper, "[Toward Structured Knowledge Reasoning: Contrastive Retrieval-Augmented Generation on Experience](YOUR_CORE_ARXIV_LINK)"[cite: 11], has been accepted to ACL 2025!
* [cite_start]**July 2025:** My paper, "[MolRAG: Unlocking the Power of Large Language Models for Molecular Property Prediction](YOUR_MOLRAG_ARXIV_LINK)"[cite: 15], has been accepted to ACL 2025!
* [cite_start]**November 2024:** My paper, "[CMR Scaling Law: Predicting Critical Mixture Ratios for Continual Pre-training of Language Models](YOUR_CMR_ARXIV_LINK)"[cite: 4], has been accepted to EMNLP 2024 as a First Author paper and selected for Oral Presentation!

---

# Publications

1.  [cite_start]**[CMR Scaling Law: Predicting Critical Mixture Ratios for Continual Pre-training of Language Models](YOUR_PAPER_PDF_LINK)** [cite: 4]
    **Jiawei Gu***, et al.
    [cite_start]EMNLP 2024, **First Author**, Oral Presentation. [cite: 4]
    * [cite_start]**Contribution**: We attempt to re-visit the scaling behavior of LLMs under the hood of CPT, and introduce Critical Mixture Ratio (CMR) and a CMR scaling law, providing a predictive framework and practical guidelines for optimizing LLM training in specialized domains, ensuring both general and domain-specific performance while managing training resources effectively[cite: 5].
    [PDF](YOUR_PAPER_PDF_LINK) &nbsp; [Slides](YOUR_SLIDES_LINK)

2.  **[Can MLLMs Reason/Think in Multimodality? [cite_start]EMMA: An Enhanced MultiModal Reasoning Benchmark](YOUR_PAPER_PDF_LINK)** [cite: 6]
    **Jiawei Gu***, et al.
    [cite_start]ICML 2025 (**Oral**), **First Author**. [cite: 6]
    * [cite_start]**Contribution**: This work introduces EMMA, a benchmark designed to evaluate multimodal reasoning across mathematics, physics, chemistry, and coding[cite: 7]. [cite_start]EMMA features tasks requiring advanced visual manipulation and cross-modal reasoning, providing insights into the limitations of current MLLMs and emphasizing the need for improved architectures and training paradigms[cite: 8].
    [PDF](YOUR_PAPER_PDF_LINK) &nbsp; [Homepage](YOUR_PAPER_HOMEPAGE_LINK) &nbsp; [Slides](YOUR_SLIDES_LINK)

3.  [cite_start]**[Boosting Decision-Making Ability of LLMs with Speculative Reward Model Cost-Effectively](YOUR_PAPER_PDF_LINK)** [cite: 9]
    **Jiawei Gu***, et al.
    [cite_start]ACL 2025 (**Oral Presentation**), **First Author**. [cite: 9]
    * [cite_start]**Contribution**: A Plug and Play framework with Speculative Reward Models (SRM), which simplifies the complex process of achieving an optimal balance between effectiveness and efficiency[cite: 10].
    [PDF](YOUR_PAPER_PDF_LINK)

4.  [cite_start]**[Toward Structured Knowledge Reasoning: Contrastive Retrieval-Augmented Generation on Experience](YOUR_PAPER_PDF_LINK)** [cite: 11]
    **Jiawei Gu***, et al.
    [cite_start]ACL 2025, **First Author**. [cite: 11]
    * [cite_start]**Contribution**: A plug-and-play method, CoRE, is proposed to improve the reasoning ability on structured knowledge[cite: 12]. [cite_start]It is training-free, lifelong, and continuous[cite: 13].
    [PDF](YOUR_PAPER_PDF_LINK)

5.  [cite_start]**[A Survey on LLM-as-a-Judge](YOUR_PAPER_PDF_LINK)** [cite: 13]
    **Jiawei Gu***, et al.
    [cite_start]Preprint, **First Author**. [cite: 13]
    * [cite_start]**Contribution**: This survey provides a comprehensive review of strategies to enhance the reliability of LLM-as-a-Judge systems, introduces a benchmark for systematic evaluation, and discusses practical applications, challenges, and future directions to guide research and deployment[cite: 14].
    [PDF](YOUR_PAPER_PDF_LINK) &nbsp; [Homepage](YOUR_PAPER_HOMEPAGE_LINK)

6.  [cite_start]**[MolRAG: Unlocking the Power of Large Language Models for Molecular Property Prediction](YOUR_PAPER_PDF_LINK)** [cite: 15]
    Second Author.
    [cite_start]ACL 2025. [cite: 15]

7.  [cite_start]**[Scaling Reasoning, Losing Control: Evaluating Instruction Following in Large Reasoning Models](YOUR_PAPER_PDF_LINK)** [cite: 16]
    Second Author.
    [cite_start]Preprint. [cite: 16]

8.  [cite_start]**[Unfolding Spatial Cognition: Evaluating Multimodal Models on Visual Simulations](YOUR_PAPER_PDF_LINK)** [cite: 17]
    Third Author.
    [cite_start]Preprint. [cite: 17]
    [PDF](YOUR_PAPER_PDF_LINK)

9.  [cite_start]**[Full Front: Benchmarking MLLMs Across the Full Front-End Engineering Workflow](YOUR_PAPER_PDF_LINK)** [cite: 16]
    Third Author.
    [cite_start]Preprint. [cite: 16]
    [PDF](YOUR_PAPER_PDF_LINK)

---
 -->
